# 知乎搜索

## 知乎搜索算法发展历程
>1，知乎的搜索算法团队成立于 2017 年底
>2，于2018年8月上线了深度语义匹配模型。
>3，在2019年4月引入了 BERT 模型，
>4，同年8月排序模型由 GBDT 升级为 DNN 模型，随后在 DNN 模型的基础上进行了一系列的迭代升级

### 由 GBDT 模型升级到 DNN 模型，主要是考虑到两点：
>1，数据量变大之后，DNN 能够实现更复杂的模型，而 GBDT 的模型容量比较有限。
>2，新的研究成果都是基于深度学习的研究，采用深度神经网络之后可以更好的应用新的研究成果，比如后面介绍的多目标排序。

##  知乎搜索架构
>1，一次搜索流程主要包括 Query 解析、召回、排序几个阶段。
>2，用户输入 Query 之后，首先要进行 Query 解析，生成查询 Query Tree 和语义表示向量。
>3，之后进入多队列的召回模块，召回阶段从召回方式上说可以分为倒排召回和向量召回，在这一环节会筛选出前 400 的文档进入到排序阶段。
>4，排序阶段又分为精排和重排序两个环节，精排阶段通过模型对多召回源的文档进行统一打分，之后将 Top16 的文档送入重排序模型进行位置的微调，最终呈现给用户

* [知乎搜索-机器学习](https://www.infoq.cn/article/HKTlJCsPZYxUQCXqCZOC)

### 多目标排序
>搜索排序任务的学习目标首先能想到的就是预测用户点击，我们最初的排序模型也是这样做的。但是 **用户点击只是第一步，单纯的点击行为并不能代表用户对搜索结果的满意，我们需要同时考虑用户在点击之后的一系列行为，比如阅读时长、点赞、收藏、关注、分享、评论等等**。这些行为都可以作为排序任务的训练目标，由于可选的目标比较多，我们通过分析这些指标与用户留存的关系进行了筛选，与点击率一起构成了排序模型的目标，开启了我们在多目标排序方面的探索

#### 基于 hard sharing 的第一版多目标排序模型
>第一版的多目标排序采用的是共享参数层+任务独立参数层的结构。共同学习的多个目标是有内在联系的，对一个目标的训练会帮助到其他目标，通过共享底层参数可以实现这个目的。在共享参数层之上又加了任务独立的参数层，使各个训练任务之间可以独立更新参数，保证互不影响。需要注意的是，不同目标的训练数据是不一样的，转化类的目标比如阅读时长、点赞、收藏，这些要用户点击之后才能发生，所以只在有点击的数据上计算 Loss。另外由于阅读时长呈长尾分布，需要用对数时长作为训练目标。在多目标模型中每个目标都会对应一个模型打分，在线上预测是需要多多个分数进行加权融合。至于不同的目标对应的具体权重我们是通过 AB 实验确定的。

#### 基于 MMOE 的第二版多目标排序
>我们采用 MMOE[2] 结构对多目标排序模型进行了升级。与 hard sharing 结构不同，MMOE 引入了 Expert，将共享参数层替换为多个 Experts 加权相加的方式，这些参数既是各个任务共享的，又通过独立权重的方式给了各个任务一定的独立性。这一版的更新在上线之后也是取得了一定的收益。